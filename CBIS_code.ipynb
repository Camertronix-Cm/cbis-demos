{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn6bkGX4BcU7Dg30I/QAs4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Camertronix-Cm/cbis-demos/blob/main/CBIS_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import imageio as imio\n",
        "import os\n",
        "import torch\n",
        "import tqdm\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import statistics\n",
        "import copy\n",
        "import math\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "xfeat = torch.hub.load('verlab/accelerated_features', 'XFeat', pretrained = True, top_k = 4096)\n",
        "#Load some example images\n"
      ],
      "metadata": {
        "id": "0apyzGjXQc8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49438645-a1b8-4e67-f752-a7433c02ff14"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/verlab/accelerated_features/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://github.com/verlab/accelerated_features/raw/main/weights/xfeat.pt\" to /root/.cache/torch/hub/checkpoints/xfeat.pt\n",
            "100%|██████████| 5.96M/5.96M [00:00<00:00, 50.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def warp_corners_and_draw_matches(ref_points, dst_points, img1, img2):\n",
        "    # Calculate the Homography matrix\n",
        "    H, mask = cv2.findHomography(ref_points, dst_points, cv2.USAC_MAGSAC, 3.5, maxIters=1_000, confidence=0.999)\n",
        "    mask = mask.flatten()\n",
        "\n",
        "    # Get corners of the first image (image1)\n",
        "    h, w = img1.shape[:2]\n",
        "    corners_img1 = np.array([[0, 0], [w-1, 0], [w-1, h-1], [0, h-1]], dtype=np.float32).reshape(-1, 1, 2)\n",
        "\n",
        "    # Warp corners to the second image (image2) space\n",
        "    warped_corners = cv2.perspectiveTransform(corners_img1, H)\n",
        "\n",
        "    # Draw the warped corners in image2\n",
        "    img2_with_corners = img2.copy()\n",
        "    for i in range(len(warped_corners)):\n",
        "        start_point = tuple(warped_corners[i-1][0].astype(int))\n",
        "        end_point = tuple(warped_corners[i][0].astype(int))\n",
        "        cv2.line(img2_with_corners, start_point, end_point, (0, 255, 0), 4)  # Using solid green for corners\n",
        "\n",
        "    # Prepare keypoints and matches for drawMatches function\n",
        "    keypoints1 = [cv2.KeyPoint(p[0], p[1], 5) for p in ref_points]\n",
        "    keypoints2 = [cv2.KeyPoint(p[0], p[1], 5) for p in dst_points]\n",
        "    matches = [cv2.DMatch(i,i,0) for i in range(len(mask)) if mask[i]]\n",
        "    #print(matches)\n",
        "\n",
        "    # Draw inlier matches\n",
        "    img_matches = cv2.drawMatches(img1, keypoints1, img2_with_corners, keypoints2, matches, None,\n",
        "                                  matchColor=(0, 255, 0), flags=2)\n",
        "\n",
        "    return img_matches\n",
        "\n",
        "\n",
        "assert cv2.__version__[0] >= '3', 'The fisheye module requires opencv version >= 3.0.0'\n",
        "def undistorted(img):\n",
        "    K = np.array([[1462.891043541062, 0.0, 1058.282670166303], [0.0, 1471.5340747924379, 590.6436713184269],[0.0, 0.0, 1.0]])\n",
        "    D = np.array([[-0.005693882560794027],\n",
        "                  [-0.27694517294013893],\n",
        "                  [0.4672123487246388],\n",
        "                  [-0.3332243527055097]])\n",
        "\n",
        "    '''K=np.array([[1446.4595928607794, 0.0, 1112.4044030939442], [0.0, 1454.7765408094683, 589.8928895307112], [0.0,\n",
        "0.0, 1.0]])\n",
        "    D=np.array([[0.06079819596228468], [-0.4708683686796481], [0.7183178914352084], [-0.5136644788920562]])'''\n",
        "    Knew = K.copy()\n",
        "    Knew[(0, 1), (0, 1)] = 0.4 * Knew[(0, 1), (0, 1)]\n",
        "    img_undistorted = cv2.fisheye.undistortImage(img, K, D=np.array([0., 0., 0., 0.]), Knew=K)\n",
        "    return img_undistorted\n",
        "\n",
        "def blend_images(img1, img2, blend_width=20):\n",
        "\n",
        "  height, width1, _ = img1.shape\n",
        "  width2 = img2.shape[1]\n",
        "\n",
        "  result = np.zeros((height, width1 + width2 - blend_width, 3), dtype=img1.dtype)\n",
        "\n",
        "  result[:, :width1 - blend_width, :] = img1[:, :width1 - blend_width, :]\n",
        "\n",
        "  for i in range(blend_width):\n",
        "    alpha = i / blend_width\n",
        "    result[:, width1 - blend_width + i, :] = (1 - alpha) * img1[:, width1 - blend_width + i, :] + alpha * img2[:, i, :]\n",
        "\n",
        "  result[:, width1:, :] = img2[:, blend_width:, :]\n",
        "\n",
        "  return result\n",
        "\n",
        "def blend_images_vertical(img1, img2, blend_height=20):\n",
        "\n",
        "  height1, width1, _ = img1.shape\n",
        "  height2 = img2.shape[0]\n",
        "\n",
        "  result = np.zeros((height1 + height2 - blend_height, width1, 3), dtype=img1.dtype)\n",
        "\n",
        "  result[:height1 - blend_height, :, :] = img1[:height1 - blend_height, :, :]\n",
        "\n",
        "  for i in range(blend_height):\n",
        "    alpha = i / blend_height  # Fraction de mélange\n",
        "    result[height1 - blend_height + i, :, :] = (1 - alpha) * img1[height1 - blend_height + i, :, :] + alpha * img2[i, :, :]\n",
        "\n",
        "  result[height1:, :, :] = img2[blend_height:, :, :]\n",
        "\n",
        "  return result\n",
        "\n",
        "def adjust_brightness(image, current_brightness,target_brightness):\n",
        "    factor = 0\n",
        "\n",
        "    if current_brightness == 0:\n",
        "        return image\n",
        "    else:\n",
        "\n",
        "        factor = target_brightness / current_brightness\n",
        "        if factor > 1.17:\n",
        "            factor = 1.17\n",
        "\n",
        "    adjusted_image = cv2.convertScaleAbs(image, alpha=factor, beta=0)\n",
        "    return adjusted_image\n",
        "\n",
        "def brightness_parameters (cropped_img1, cropped_img2):\n",
        "\n",
        "    current_brightness1= np.mean(cropped_img1)\n",
        "    current_brightness2 = np.mean(cropped_img2)\n",
        "    current_brightness = (current_brightness1 +current_brightness2)/2\n",
        "\n",
        "    difference = current_brightness1-current_brightness2\n",
        "\n",
        "    if -16 <= difference <= 16:\n",
        "\n",
        "        entier = int(difference)\n",
        "        decimal = abs(difference - entier)\n",
        "\n",
        "        decimal_str = str(decimal)[2:]\n",
        "\n",
        "        if len(decimal_str) > 1 and int(decimal_str[1]) >= 5:\n",
        "            valeur_finale = entier + 1\n",
        "        else:\n",
        "            valeur_finale = entier\n",
        "\n",
        "        if difference < 0:\n",
        "            brightness_correction = valeur_finale * (-2)\n",
        "        elif difference > 0:\n",
        "            brightness_correction = valeur_finale * (-2)\n",
        "        else:  # difference == 0\n",
        "            brightness_correction = 0\n",
        "    else:\n",
        "        brightness_correction = 0\n",
        "\n",
        "    if current_brightness1 <current_brightness2:\n",
        "\n",
        "            target_brightness = current_brightness2\n",
        "            if target_brightness/current_brightness < 1:\n",
        "                cropped_img1 = adjust_brightness(cropped_img1, current_brightness,target_brightness+brightness_correction)\n",
        "\n",
        "            if target_brightness/current_brightness> 1:\n",
        "                cropped_img2 = adjust_brightness(cropped_img2, current_brightness,target_brightness+brightness_correction)\n",
        "\n",
        "    elif current_brightness1 >current_brightness2:\n",
        "\n",
        "            target_brightness = current_brightness1\n",
        "            if target_brightness/current_brightness < 1:\n",
        "                cropped_img2 = adjust_brightness(cropped_img2, current_brightness,target_brightness+brightness_correction)\n",
        "\n",
        "            if target_brightness/current_brightness> 1:\n",
        "                cropped_img1 = adjust_brightness(cropped_img1, current_brightness,target_brightness+brightness_correction)\n",
        "\n",
        "\n",
        "    return cropped_img1, cropped_img2\n",
        "\n",
        "\n",
        "def pad_imagewidth(image, target_width,side):\n",
        "  height, width = image.shape[:2]\n",
        "  if side=='r':\n",
        "    padding_left=0\n",
        "    padding_right = target_width - width\n",
        "  elif side=='l':\n",
        "    padding_right=0\n",
        "    padding_left = target_width - width\n",
        "\n",
        "  # Pad the image with black borders on left and right\n",
        "  padded_image = cv2.copyMakeBorder(image, 0, 0, padding_left, padding_right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
        "\n",
        "  return padded_image\n",
        "\n",
        "def image_translation(img1, img2, shift_y1,repetitions):\n",
        "\n",
        "    height, width = img1.shape[:2]\n",
        "    height2, width2 = img2.shape[:2]\n",
        "\n",
        "    if shift_y1 > 0:\n",
        "        last_line = img1[-1:, :, :]\n",
        "        repeat_line = np.tile(last_line, (repetitions, 1, 1))\n",
        "        new_height1 = img1.shape[0] + repetitions\n",
        "        img_resultat = np.zeros((new_height1, img1.shape[1], img1.shape[2]), dtype=img1.dtype)\n",
        "\n",
        "        img_resultat[:img1.shape[0], :, :] = img1\n",
        "        img_resultat[img1.shape[0]:, :, :] = repeat_line\n",
        "        img1 = img_resultat\n",
        "\n",
        "        first_line = img2[0:1, :, :]\n",
        "        repeat_line2 = np.tile(first_line, (repetitions, 1, 1))\n",
        "        new_height2 = img2.shape[0] + repetitions\n",
        "        img_resultat2 = np.zeros((new_height2, img2.shape[1], img2.shape[2]), dtype=img2.dtype)\n",
        "\n",
        "        img_resultat2[:repetitions, :, :] = repeat_line2\n",
        "        img_resultat2[repetitions:, :, :] = img2\n",
        "        img2 = img_resultat2\n",
        "    else:\n",
        "        last_line = img2[-1:, :, :]\n",
        "        repeat_line2 = np.tile(last_line, (repetitions, 1, 1))\n",
        "        new_height2 = img2.shape[0] + repetitions\n",
        "        img_resultat2 = np.zeros((new_height2, img2.shape[1], img2.shape[2]), dtype=img2.dtype)\n",
        "\n",
        "        img_resultat2[:img2.shape[0], :, :] = img2\n",
        "        img_resultat2[img2.shape[0]:, :, :] = repeat_line2\n",
        "        img2 = img_resultat2\n",
        "\n",
        "        first_line = img1[0:1, :, :]\n",
        "        repeat_line = np.tile(first_line, (repetitions, 1, 1))\n",
        "        new_height1 = img1.shape[0] + repetitions\n",
        "        img_resultat = np.zeros((new_height1, img1.shape[1], img1.shape[2]), dtype=img1.dtype)\n",
        "\n",
        "        img_resultat[:repetitions, :, :] = repeat_line\n",
        "        img_resultat[repetitions:, :, :] = img1\n",
        "        img1 = img_resultat\n",
        "\n",
        "    return img1, img2\n",
        "\n",
        "def translate_and_concatenate(img1, img2, dy):\n",
        "\n",
        "  h1, w1 = img1.shape[:2]\n",
        "  h2, w2 = img2.shape[:2]\n",
        "\n",
        "  # Calculate the new height of the translated image\n",
        "  new_h2 = h2 + abs(dy)\n",
        "\n",
        "  # Create a new image with the calculated height\n",
        "  translated_img2 = np.zeros((new_h2, w2, 3), dtype=img2.dtype)\n",
        "  pad_img1=np.zeros((new_h2, w1, 3), dtype=img1.dtype)\n",
        "\n",
        "  # Copy the original image to the new image, applying the translation\n",
        "  if dy >= 0:\n",
        "    translated_img2[dy:, :] = img2\n",
        "    pad_img1[:new_h2-dy, :] = img1\n",
        "  else:\n",
        "    translated_img2[:new_h2+dy, :] = img2\n",
        "    pad_img1[abs(dy):, :] = img1\n",
        "\n",
        "  concatenated_img=blend_images(pad_img1,translated_img2,20)\n",
        "\n",
        "  return concatenated_img\n",
        "\n",
        "def image_stitching(im1, im2):\n",
        "  im1_undistorted=undistorted(im1)\n",
        "  im2_undistorted=undistorted(im2)\n",
        "  debut=time.time()\n",
        "  #im1_undistorted=im1\n",
        "  #im2_undistorted=im2\n",
        "  mkpts_0, mkpts_1 = xfeat.match_xfeat(im1_undistorted, im2_undistorted, top_k = 4096, min_cossim=-1 )\n",
        "  canvas = warp_corners_and_draw_matches(mkpts_0, mkpts_1, im1_undistorted, im2_undistorted)\n",
        "  category1, category2, category3, category4, category5, category6, category7,category8,category9,category10,category11,category12,category13,category14,category15,category16,category17,category18,category19,category20, summoy, nbre =0,0,0,0,0,0,0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
        "  yaxis_class=[[0,100],[100,200],[200,300],[300,400],[400,500],[500,600],[600,700],[700,800],[800,900],[900,1000],[1000,1080]]\n",
        "  xaxis_class=[[0,100],[100,200],[200,300],[300,400],[400,500],[500,600],[600,700],[700,800],[800,900],[900,950],[950,1000],[1000,1100],[1100,1200],[1200,1300],[1300,1400],[1400,1500],[1500,1600],[1600,1700],[1700,1800],[1800,1900],[1900,2000]]\n",
        "  sum_result=None\n",
        "  fixed_point=[]\n",
        "  average_xaxis=[]\n",
        "  average_yaxis=[]\n",
        "  filtered_setleft,filtered_setright=[],[]\n",
        "  k=0\n",
        "  i,avg_abs,avg_ord1, avg_ord2,ydiff,bad_frame=0,0,0,0,0,0\n",
        "  area,ydiff_left=[],[]\n",
        "  concatpoint=None\n",
        "\n",
        "  yleft_right,yright_left=0,0\n",
        "  for y in range(len(mkpts_0)):\n",
        "    if mkpts_0[y][0]>mkpts_1[y][0]:\n",
        "      if mkpts_0[y][1]>mkpts_1[y][1]:\n",
        "        filtered_setleft.append([mkpts_0[y],mkpts_1[y]])\n",
        "        ydiff_left.append(mkpts_0[y][1]-mkpts_1[y][1])\n",
        "        yleft_right+=1\n",
        "      elif mkpts_0[y][1]<mkpts_1[y][1]:\n",
        "        filtered_setright.append([mkpts_0[y],mkpts_1[y]])\n",
        "        ydiff+=mkpts_1[y][1]-mkpts_0[y][1]\n",
        "        yright_left+=1\n",
        "  ydiff=ydiff/yright_left\n",
        "  ydiff_left=statistics.mean(ydiff_left)\n",
        "\n",
        "  filtered_setleft=[m for m in filtered_setleft if m[0][1]-m[1][1]<ydiff_left]\n",
        "  filtered_setright=[m for m in filtered_setright if  m[1][1]-m[0][1]<ydiff]\n",
        "\n",
        "\n",
        "  if yleft_right>yright_left:\n",
        "\n",
        "    for elt in xaxis_class:\n",
        "      xdiff=[]\n",
        "\n",
        "      summoy1,summoy,nbre=0,0,0\n",
        "      for m,n in filtered_setleft:\n",
        "        if m[0]>= elt[0] and m[0]<elt[1] :\n",
        "          xdiff.append(m[0]-n[0])\n",
        "      try:\n",
        "        avgxdiff=statistics.mean(xdiff)\n",
        "        average_xaxis.append([avgxdiff,len(xdiff)])\n",
        "      except statistics.StatisticsError:\n",
        "        avgxdiff=0\n",
        "        average_xaxis.append([avgxdiff,len(xdiff)])\n",
        "\n",
        "    gen_avg=statistics.mean([sublist[0] for sublist in average_xaxis])\n",
        "\n",
        "    diff_avg=[]\n",
        "    for j in range(len(average_xaxis)-1):\n",
        "      if average_xaxis[j][1]!=0 and average_xaxis[j+1][1]!=0:\n",
        "        diff_avg.append([abs(average_xaxis[j][0] -average_xaxis[j+1][0]),j])\n",
        "\n",
        "    small_diff,succ=[], 10\n",
        "    while len(small_diff)==0:\n",
        "      small_diff=[num for num in diff_avg if num[0]<=succ and average_xaxis[num[1]][1]!=0]\n",
        "      succ+=5\n",
        "\n",
        "    result = []\n",
        "    current_group = []\n",
        "    for element in small_diff:\n",
        "      if not current_group or abs(element[1] - current_group[-1][1]) <= 1:\n",
        "        current_group.append(element)\n",
        "      else:\n",
        "        result.append(current_group)\n",
        "        current_group = [element]\n",
        "    if current_group:\n",
        "      result.append(current_group)\n",
        "\n",
        "    diff_genavg=[]\n",
        "    area= [[] for _ in range(len(result))]\n",
        "    print(\"area\",area)\n",
        "    for e in range(len(result)):\n",
        "\n",
        "      area[e].append(xaxis_class[result[e][0][1]][0])\n",
        "      area[e].append(xaxis_class[result[e][-1][1]+1][1])\n",
        "\n",
        "    diff_genavg=[]\n",
        "    if len(area)>1:\n",
        "      filtered_set=[[] for _ in range(len(result))]\n",
        "      for i in range (len(area)):\n",
        "\n",
        "        data=[m[0]-n[0] for m,n in filtered_setleft if area[i][0] <= m[0] <= area[i][1]]\n",
        "        n = len(data)\n",
        "        class_avg = statistics.mean(data)\n",
        "        var= sum((x - class_avg) ** 2 for x in data) / n\n",
        "        ecart=math.sqrt(var)\n",
        "        diff_genavg.append([area[i],abs(class_avg-gen_avg)/n,[class_avg,ecart]])\n",
        "\n",
        "        diff_genavg=sorted(diff_genavg, key=lambda x:x[1] )\n",
        "\n",
        "      area=[m[0] for m in diff_genavg ]\n",
        "\n",
        "      filtered_setcopy=[]\n",
        "      for i in range (len(area)):\n",
        "\n",
        "        error=diff_genavg[i][-1][1]/2\n",
        "        class_avg=diff_genavg[i][-1][0]\n",
        "\n",
        "        while len(filtered_set[i])==0 and error<diff_genavg[i][-1][1]/2+10:\n",
        "\n",
        "\n",
        "          if class_avg<gen_avg+15:\n",
        "            filtered_set[i]=[[m,n,m[0]-n[0]-class_avg] for m,n in filtered_setleft if area[i][0] <= m[0] <= area[i][1] and class_avg <m[0]-n[0]<class_avg+error]\n",
        "          else:\n",
        "            filtered_set[i]=[[m,n,m[0]-n[0]-class_avg] for m,n in filtered_setleft if area[i][0] <= m[0] <= area[i][1] and class_avg-error <m[0]-n[0]<class_avg+error]\n",
        "          error+=5\n",
        "\n",
        "        if len(filtered_set[i])>0:\n",
        "          filtered_set[i]=sorted(filtered_set[i], key=lambda x:x[-1] )\n",
        "          filtered_set[i]=[elt[:2] for elt in filtered_set[i]]\n",
        "          filtered_setcopy.append(filtered_set[i])\n",
        "\n",
        "      try:\n",
        "\n",
        "        concatpoint=filtered_setcopy[0][int(len(filtered_setcopy)/2)][:2]\n",
        "\n",
        "      except IndexError:\n",
        "        print(\"pas de points\")\n",
        "\n",
        "    else:\n",
        "      filtered_setleft=[[m,n] for m,n in filtered_setleft if area[0][0] <= m[0] <= area[0][1]]\n",
        "      try:\n",
        "        concatpoint=filtered_setleft[int(len(filtered_setleft)/2)][:2]\n",
        "\n",
        "      except IndexError:\n",
        "        print(\"pas de points\")\n",
        "\n",
        "  else:\n",
        "\n",
        "    for elt in xaxis_class:\n",
        "      xdiff=[]\n",
        "\n",
        "      summoy1,summoy,nbre=0,0,0\n",
        "      for m,n in filtered_setright:\n",
        "        if elt[0]<= m[0]<elt[1] :\n",
        "\n",
        "          xdiff.append(m[0]-n[0])\n",
        "      try:\n",
        "        avgxdiff=statistics.mean(xdiff)\n",
        "        average_xaxis.append([avgxdiff,len(xdiff)])\n",
        "      except statistics.StatisticsError:\n",
        "        avgxdiff=0\n",
        "        average_xaxis.append([avgxdiff,len(xdiff)])\n",
        "    gen_avg=statistics.mean([sublist[0] for sublist in average_xaxis])\n",
        "\n",
        "    diff_avg=[]\n",
        "    for j in range(len(average_xaxis)-1):\n",
        "      if average_xaxis[j][1]!=0 and average_xaxis[j+1][1]!=0:\n",
        "        diff_avg.append([abs(average_xaxis[j][0] -average_xaxis[j+1][0]),j])\n",
        "\n",
        "    small_diff,succ=[], 10\n",
        "\n",
        "    while len(small_diff)==0:\n",
        "      small_diff=[num for num in diff_avg if num[0]<=succ and average_xaxis[num[1]][1]!=0]\n",
        "      succ+=5\n",
        "\n",
        "    copysmall_diff=copy.deepcopy(small_diff)\n",
        "    result = []\n",
        "    current_group = []\n",
        "    for element in small_diff:\n",
        "      if not current_group or abs(element[1] - current_group[-1][1]) <= 1:\n",
        "        current_group.append(element)\n",
        "      else:\n",
        "        result.append(current_group)\n",
        "        current_group = [element]\n",
        "    if current_group:\n",
        "      result.append(current_group)\n",
        "\n",
        "    area= [[] for _ in range(len(result))]\n",
        "    diff_genavg=[]\n",
        "\n",
        "    for e in range(len(result)):\n",
        "\n",
        "      area[e].append(xaxis_class[result[e][0][1]][0])\n",
        "      area[e].append(xaxis_class[result[e][-1][1]+1][1])\n",
        "\n",
        "    diff_genavg=[]\n",
        "    if len(area)>1:\n",
        "      filtered_set=[[] for _ in range(len(result))]\n",
        "\n",
        "      for i in range (len(area)):\n",
        "\n",
        "        data=[m[0]-n[0] for m,n in filtered_setright if area[i][0] <= m[0] <= area[i][1]]\n",
        "        n = len(data)\n",
        "        class_avg = statistics.mean(data)\n",
        "        var= sum((x - class_avg) ** 2 for x in data) / n\n",
        "        ecart=math.sqrt(var)\n",
        "        diff_genavg.append([area[i],abs(class_avg-gen_avg)/n,[class_avg,ecart]])\n",
        "\n",
        "        diff_genavg=sorted(diff_genavg, key=lambda x:x[1] )\n",
        "\n",
        "      area=[m[0] for m in diff_genavg ]\n",
        "      print(\"area\",area)\n",
        "      filtered_setcopy=[]\n",
        "      for i in range (len(area)):\n",
        "\n",
        "        error=diff_genavg[i][-1][1]/2\n",
        "        class_avg=diff_genavg[i][-1][0]\n",
        "\n",
        "        while len(filtered_set[i])==0 and error<diff_genavg[i][-1][1]/2+10:\n",
        "\n",
        "          if class_avg<gen_avg+15:\n",
        "            filtered_set[i]=[[m,n,m[0]-n[0]-class_avg] for m,n in filtered_setright if area[i][0] <= m[0] <= area[i][1] and class_avg < m[0]-n[0]<class_avg+error]\n",
        "          else:\n",
        "            filtered_set[i]=[[m,n,m[0]-n[0]-class_avg] for m,n in filtered_setright if area[i][0] <= m[0] <= area[i][1] and class_avg-error <m[0]-n[0]<class_avg+error]\n",
        "          error+=5\n",
        "\n",
        "        if len(filtered_set[i])>0:\n",
        "          filtered_set[i]=sorted(filtered_set[i], key=lambda x:x[-1] )\n",
        "          filtered_set[i]=[elt[:2] for elt in filtered_set[i]]\n",
        "          filtered_setcopy.append(filtered_set[i])\n",
        "\n",
        "      try:\n",
        "\n",
        "        concatpoint=filtered_setcopy[0][int(len(filtered_setcopy)/2)][:2]\n",
        "\n",
        "      except IndexError:\n",
        "        print(\"pas de points\")\n",
        "\n",
        "    else:\n",
        "      filtered_setright=[[m,n] for m,n in filtered_setright if area[0][0] <= m[0] <= area[0][1]]\n",
        "      try:\n",
        "        concatpoint=filtered_setright[int(len(filtered_setright)/2)][:2]\n",
        "\n",
        "      except IndexError:\n",
        "        print(\"pas de points\")\n",
        "\n",
        "\n",
        "  if concatpoint!=None:\n",
        "    print(\"concatpoint\",concatpoint)\n",
        "\n",
        "    x1,y1=concatpoint[0]\n",
        "    x2,y2=concatpoint[1]\n",
        "    shift_y=math.ceil(y1-y2)\n",
        "    cropped_img1 = im1_undistorted[0:im1_undistorted.shape[0],0:int(x1)+15]\n",
        "    cropped_img2 = im2_undistorted[0:im2_undistorted.shape[0],int(x2)-15:im2_undistorted.shape[1]]\n",
        "    cropped_img1,cropped_img2=brightness_parameters(cropped_img1,cropped_img2)\n",
        "    result_horizontal=translate_and_concatenate(cropped_img1,cropped_img2,shift_y)\n",
        "\n",
        "  else:\n",
        "    result_horizontal=None\n",
        "\n",
        "  return result_horizontal,concatpoint\n",
        "\n",
        "def reduced_concatenation(img1,img2, fixed_point) :\n",
        "  im1_undistorted=undistorted(img1)\n",
        "  im2_undistorted=undistorted(img2)\n",
        "  #im1_undistorted=img1\n",
        "  #im2_undistorted=img2\n",
        "  x1, y1 = fixed_point[0]\n",
        "  x2, y2 = fixed_point[1]\n",
        "  cropped_img1 = im1_undistorted[0:im1_undistorted.shape[0],0:int(x1)+15]\n",
        "  cropped_img2 = im2_undistorted[0:im2_undistorted.shape[0],int(x2)-15:im2_undistorted.shape[1]]\n",
        "  cropped_img1,cropped_img2=brightness_parameters(cropped_img1,cropped_img2)\n",
        "  shift_y=math.ceil(y1-y2)\n",
        "  sum_result=translate_and_concatenate(cropped_img1,cropped_img2,shift_y)\n",
        "  return sum_result\n"
      ],
      "metadata": {
        "id": "CjDkdXKE8Vri"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im1 = cv2.imread('/content/sample_data/image1.jpg')\n",
        "im2 = cv2.imread('/content/sample_data/image2.jpg')\n",
        "result=image_stitching(im1,im2)\n",
        "cv2.imwrite(\"/content/sample_data/result.jpg\", result)"
      ],
      "metadata": {
        "id": "DXHxBc04T6_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def capture_and_concatenate(video_directory, output_file):\n",
        "    # Load videos\n",
        "    video_files = [os.path.join(video_directory, f) for f in os.listdir(video_directory) if f.endswith('.mp4')]\n",
        "    video_files.sort()\n",
        "    print(video_files)\n",
        "\n",
        "    if len(video_files) < 2:\n",
        "        print(\"Erreur : Au moins deux fichiers vidéo sont nécessaires pour la concaténation.\")\n",
        "        return\n",
        "\n",
        "    # get video properties\n",
        "    def get_video_properties(video_path):\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames=int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        cap.release()\n",
        "        return (width, height), fps, total_frames\n",
        "\n",
        "    (width1, height1), fps1, total_frames1 = get_video_properties(video_files[0])\n",
        "    (width2, height2), fps2, total_frames2 = get_video_properties(video_files[1])\n",
        "\n",
        "    frame_height = min(height1, height2)\n",
        "    fps=5\n",
        "\n",
        "    print(f\"Dimensions initiales : Hauteur = {frame_height}, FPS = {fps}\",total_frames1,total_frames2,fps1,fps2)\n",
        "\n",
        "    caps = [cv2.VideoCapture(video_file) for video_file in video_files[:2]]\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = None\n",
        "    refresh,i,fixed_points=0,0,[]\n",
        "\n",
        "    while True:\n",
        "        frames = []\n",
        "        reached_end = False\n",
        "\n",
        "        for cap in caps:\n",
        "            grabbed, frame = cap.read()\n",
        "            if grabbed:\n",
        "\n",
        "                frames.append(frame)\n",
        "\n",
        "            else:\n",
        "                reached_end = True\n",
        "\n",
        "        if reached_end:\n",
        "            print(\"Fin de l'une des vidéos. Arrêt du processus.\")\n",
        "            break\n",
        "\n",
        "        if len(frames) == 2:\n",
        "\n",
        "          essai=False\n",
        "          #if refresh % 6 == 0:\n",
        "          result_frame,fixed_point=image_stitching(frames[0], frames[1])\n",
        "          if result_frame is None:\n",
        "            print(\"concatenation failed\")\n",
        "            if len(fixed_points)>0:\n",
        "              result_frame=reduced_concatenation(frames[0], frames[1],fixed_points[-1])\n",
        "\n",
        "          else:\n",
        "              fixed_points.append(fixed_point)\n",
        "          #else:\n",
        "            #result_frame=reduced_concatenation(frames[0], frames[1],fixed_point)\n",
        "\n",
        "          refresh+=1\n",
        "\n",
        "\n",
        "          if result_frame is not None and result_frame.shape[0] > 0 and result_frame.shape[1] > 0:\n",
        "            print(f\"Frame concaténée écrite avec succès. Dimensions : {result_frame.shape}\")\n",
        "\n",
        "            frame_width = 2500\n",
        "            frame_height=1100\n",
        "\n",
        "            if out is None:\n",
        "\n",
        "              out = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc('X', 'V', 'I', 'D'), fps, (frame_width, frame_height))\n",
        "\n",
        "            print(\"result_frame.shape\", refresh,result_frame.shape)\n",
        "            result_frame = cv2.resize(result_frame, (frame_width, frame_height))\n",
        "            out.write(result_frame)\n",
        "\n",
        "        else:\n",
        "          print(\"Erreur : Moins de deux frames disponibles pour la concaténation.\")\n",
        "\n",
        "    for cap in caps:\n",
        "        cap.release()\n",
        "    if out is not None:\n",
        "      out.release()\n",
        "    #cv2.destroyAllWindows()\n",
        "\n",
        "capture_and_concatenate('/content/sample_data/videos', 'output_video1.mp4')\n"
      ],
      "metadata": {
        "id": "say1QtjXB5D8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(\"output_video1.mp4\")\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "total_frames=int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "cap.release()\n",
        "print(f\"Dimensions initiales : Hauteur = {height}, FPS = {fps}\",total_frames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNk9ATrJv5qd",
        "outputId": "b7f88f54-8ae9-449e-d1b2-26a7e9ebc2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions initiales : Hauteur = 1100, FPS = 5.0 86\n"
          ]
        }
      ]
    }
  ]
}